{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.linear_model import Perceptron \n",
    "\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>two places invest all my money if could printi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awesome google driverless cars will help the b...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if google maps can not keep up with road const...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autonomous cars seem way overhyped given the t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just saw google self driving car on it was pai...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  two places invest all my money if could printi...         5\n",
       "1  awesome google driverless cars will help the b...         5\n",
       "2  if google maps can not keep up with road const...         2\n",
       "3  autonomous cars seem way overhyped given the t...         2\n",
       "4  just saw google self driving car on it was pai...         3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      "text         100 non-null object\n",
      "sentiment    100 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "my_df.dropna(inplace=True)\n",
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = my_df.text\n",
    "y = my_df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\",format(len(x_train),(len(x_train[y_train == 0]) / (len(x_train)*1.))*100,(len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "#print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\", format(len(x_validation),(len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,(len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))\n",
    "#print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\",format(len(x_test),(len(x_test[y_test == 0]) / (len(x_test)*1.))*100,(len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix],model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [t.split() for t in x_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(tokenized_train)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'mayor', 'of', 'new', 'york', 'was', 'there']\n"
     ]
    }
   ],
   "source": [
    "sent = [u'the', u'mayor', u'of', u'new', u'york', u'was', u'there']\n",
    "print(bigram[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will',\n",
       " 'driverless_cars',\n",
       " 'eventually',\n",
       " 'replace',\n",
       " 'taxi',\n",
       " 'drivers',\n",
       " 'in',\n",
       " 'cities']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[x_train[5].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_tweets_bg(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(bigram[t.split()], [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v_bg = labelize_tweets_bg(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBOW Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 100/100 [00:00<00:00, 369216.90it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dbow.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 227827.49it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 502311.86it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 471800.22it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 471800.22it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 518455.38it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 531597.47it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 523633.46it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 498135.87it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 521031.55it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 290665.56it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 320910.79it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 535671.01it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 512751.10it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 523633.46it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 502311.86it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 538421.57it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 539807.46it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 540503.09it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 276304.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 502914.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 528916.02it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 186579.36it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 502914.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 482658.69it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 413231.92it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 127680.49it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 418175.87it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 138700.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 233535.86it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 436452.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_bg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dbow.alpha -= 0.002\n",
    "    model_bg_dbow.min_alpha = model_bg_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_bg = get_vectors(model_bg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_bg = get_vectors(model_bg_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "clf1 = NearestCentroid()\n",
    "clf1.fit(train_vecs_dbow_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(validation_vecs_dbow_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dbow.save('d2v_model_bg_dbow.doc2vec')\n",
    "model_bg_dbow = Doc2Vec.load('d2v_model_bg_dbow.doc2vec')\n",
    "model_bg_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBOW Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 100/100 [00:00<00:00, 75018.85it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmc.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 210981.09it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 355750.98it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 189701.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 92142.00it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 186247.96it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 294337.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 451000.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 406424.81it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 421962.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 259227.69it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 258429.08it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 373158.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 209296.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 368892.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 318232.47it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 211513.06it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 408006.23it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 384798.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 211406.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 365995.11it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 394943.88it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 206108.30it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 196087.14it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 295998.87it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 331042.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 460406.59it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 337977.76it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 228821.82it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 282444.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 273958.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_bg_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmc.alpha -= 0.002\n",
    "    model_bg_dmc.min_alpha = model_bg_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dbow_dmm_bg.most_similar('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dbow_dmm_bg.most_similar(positive=['uber','audi'], negative=['car'], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmc_bg = get_vectors(model_bg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_bg = get_vectors(model_bg_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc_bg, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmc_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmc.save('d2v_model_bg_dmc.doc2vec')\n",
    "model_bg_dmc = Doc2Vec.load('d2v_model_bg_dmc.doc2vec')\n",
    "model_bg_dmc.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMM BIgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 100/100 [00:00<00:00, 80197.02it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmm = Doc2Vec(dm=1, dm_mean=1, size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmm.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 132815.20it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 251910.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 127719.37it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 319687.80it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 341277.79it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 226108.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 480447.19it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 226841.75it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 261816.73it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 312541.28it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 316551.25it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 342392.16it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 243289.10it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 163139.01it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 62892.55it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 92855.97it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 127061.62it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 22142.88it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 334474.00it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 119156.36it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 160578.25it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 285715.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 313475.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 278691.30it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 251306.41it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 245137.58it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 473397.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 311381.14it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 224654.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 328707.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_bg_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmm.alpha -= 0.002\n",
    "    model_bg_dmm.min_alpha = model_bg_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmm_bg = get_vectors(model_bg_dmm, x_train, 100)\n",
    "validation_vecs_dmm_bg = get_vectors(model_bg_dmm, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmm_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmm.save('d2v_model_bg_dmm.doc2vec')\n",
    "model_bg_dmm = Doc2Vec.load('d2v_model_bg_dmm.doc2vec')\n",
    "model_bg_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_dmc_bg = get_concat_vectors(model_bg_dbow,model_bg_dmc, x_train, 200)\n",
    "validation_vecs_dbow_dmc_bg = get_concat_vectors(model_bg_dbow,model_bg_dmc, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmc_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_dmc_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_dmm_bg = get_concat_vectors(model_bg_dbow,model_bg_dmm, x_train, 200)\n",
    "validation_vecs_dbow_dmm_bg = get_concat_vectors(model_bg_dbow,model_bg_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_dmm_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_phrases = Phrases(bigram[tokenized_train])\n",
    "trigram = Phraser(tg_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will',\n",
       " 'driverless_cars',\n",
       " 'eventually',\n",
       " 'replace',\n",
       " 'taxi',\n",
       " 'drivers',\n",
       " 'in',\n",
       " 'cities']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram[bigram[x_train[5].split()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_tweets_tg(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(trigram[bigram[t.split()]], [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v_tg = labelize_tweets_tg(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 100/100 [00:00<00:00, 138106.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model_tg_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_tg_dbow.build_vocab([x for x in tqdm(all_x_w2v_tg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 340170.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 284552.51it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 284166.94it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 275578.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 421962.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 408403.51it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 374491.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 333145.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 446677.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 248625.01it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 450516.00it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 366314.76it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 337977.76it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 303056.65it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 222155.93it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 311381.14it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 309542.73it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 212800.81it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 332090.58it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 231473.73it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 408403.51it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 298314.65it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 184203.07it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 395316.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 306825.46it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 224654.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 101409.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 288268.32it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 526922.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 321402.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_tg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_tg)]), total_examples=len(all_x_w2v_tg), epochs=1)\n",
    "    model_tg_dbow.alpha -= 0.002\n",
    "    model_tg_dbow.min_alpha = model_tg_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_tg = get_vectors(model_tg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_tg = get_vectors(model_tg_dbow, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_tg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dbow.save('d2v_model_tg_dbow.doc2vec')\n",
    "model_tg_dbow = Doc2Vec.load('d2v_model_tg_dbow.doc2vec')\n",
    "model_tg_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMC Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 100/100 [00:00<00:00, 149636.25it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_tg_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_tg_dmc.build_vocab([x for x in tqdm(all_x_w2v_tg)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 158995.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 173965.33it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 116153.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 77300.11it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 323634.57it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 116800.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 362202.42it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 186662.39it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 196454.52it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 215534.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 115577.40it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 307725.90it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 343795.41it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 99109.26it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 295790.13it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 67055.22it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 159479.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 196087.14it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 254508.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 266643.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 279247.94it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 54225.00it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 220636.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 322638.77it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 146193.94it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 116735.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 62415.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 72628.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 264458.01it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 166374.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_tg_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v_tg)]), total_examples=len(all_x_w2v_tg), epochs=1)\n",
    "    model_tg_dmc.alpha -= 0.002\n",
    "    model_tg_dmc.min_alpha = model_tg_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmc_tg = get_vectors(model_tg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_tg = get_vectors(model_tg_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmc_tg, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dmc.save('d2v_model_tg_dmc.doc2vec')\n",
    "model_tg_dmc = Doc2Vec.load('d2v_model_tg_dmc.doc2vec')\n",
    "model_tg_dmc.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMM trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|██████████| 100/100 [00:00<00:00, 245712.01it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_tg_dmm = Doc2Vec(dm=1, dm_mean=1, size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_tg_dmm.build_vocab([x for x in tqdm(all_x_w2v_tg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 250705.56it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 238042.22it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 232629.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 173318.35it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 210135.47it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 75818.94it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 188932.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 168310.75it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 210030.25it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 144134.16it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 73597.19it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 104258.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 312541.28it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 181179.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 298739.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 109397.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 141843.22it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 275578.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 122425.69it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 91578.69it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 347210.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 309771.34it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 247014.37it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 81112.05it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 234843.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 309542.73it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 224174.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 310689.19it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 266813.23it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 247451.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_tg_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v_tg)]), total_examples=len(all_x_w2v_tg), epochs=1)\n",
    "    model_tg_dmm.alpha -= 0.002\n",
    "    model_tg_dmc.min_alpha = model_tg_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmm_tg = get_vectors(model_tg_dmm, x_train, 100)\n",
    "validation_vecs_dmm_tg = get_vectors(model_tg_dmm, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dmm_tg, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dmm.save('d2v_model_tg_dmm.doc2vec')\n",
    "model_tg_dmm = Doc2Vec.load('d2v_model_tg_dmm.doc2vec')\n",
    "model_tg_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_dmc_tg = get_concat_vectors(model_tg_dbow,model_tg_dmc, x_train, 200)\n",
    "validation_vecs_dbow_dmc_tg = get_concat_vectors(model_tg_dbow,model_tg_dmc, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmc_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_dmc_tg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dbow_dmm_tg = get_concat_vectors(model_tg_dbow,model_tg_dmm, x_train, 200)\n",
    "validation_vecs_dbow_dmm_tg = get_concat_vectors(model_tg_dbow,model_tg_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm_tg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_dbow_dmm_tg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tg_dmm.save('d2v_model_ug_dbow.doc2vec')\n",
    "model_ug_dbow = Doc2Vec.load('d2v_model_ug_dbow.doc2vec')\n",
    "model_tg_dmm = Doc2Vec.load('d2v_model_tg_dmm.doc2vec')\n",
    "model_ug_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_tg_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_ugdbow_tgdmm = get_concat_vectors(model_ug_dbow,model_tg_dmm, x_train, 200)\n",
    "validation_vecs_ugdbow_tgdmm = get_concat_vectors(model_ug_dbow,model_tg_dmm, x_validation, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_ugdbow_tgdmm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_vecs_ugdbow_tgdmm, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "d2v_ugdbow_tgdmm_mm = mmscaler.fit_transform(train_vecs_ugdbow_tgdmm)\n",
    "d2v_ugdbow_tgdmm_mm_val = mmscaler.fit_transform(validation_vecs_ugdbow_tgdmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"null accuracy: {0:.2f}%\",format(null_accuracy*100))\n",
    "    print(\"accuracy score: {0:.2f}%\",format(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print(\"model is {0:.2f}% more accurate than null accuracy\",format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print(\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print(\"model is {0:.2f}% less accurate than null accuracy\",format((null_accuracy-accuracy)*100))\n",
    "    #print \"train and test time: {0:.2f}s\".format(train_test_time)\n",
    "   # print \"-\"*80\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "def classifier_comparator_d2v(train_vectors,validation_vectors, classifier=zipped_clf1):\n",
    "    result = []\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([('classifier', c)])\n",
    "        print(\"Validation result for {}\",format(n))\n",
    "        print(c)\n",
    "        clf_accuracy,tt_time = accuracy_summary(checker_pipeline, train_vectors, y_train, validation_vectors, y_validation)\n",
    "        result.append((n,clf_accuracy,tt_time))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
